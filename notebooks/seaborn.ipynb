{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# git2net analysis for the seaborn repository\n",
    "\n",
    "First we clone the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygit2 as git2\n",
    "import os\n",
    "import shutil\n",
    "import git2net\n",
    "import pathpy as pp\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "\n",
    "git_repo_url = 'https://github.com/mwaskom/seaborn.git'\n",
    "local_directory = '.'\n",
    "git_repo_dir = 'notebooks/repos/seaborn4analysis'\n",
    "sqlite_db_file = 'notebooks/databases/seaborn.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(git_repo_dir):\n",
    "    shutil.rmtree(git_repo_dir)\n",
    "\n",
    "repo = git2.clone_repository(git_repo_url, git_repo_dir) # Clones a non-bare repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the database for it. We will try with max_modification=100, so that most commits are processed.\n",
    "\n",
    "Mine repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove database if exists\n",
    "#if os.path.exists(sqlite_db_file):\n",
    "#    os.remove(sqlite_db_file)\n",
    "\n",
    "max_modifications = 100\n",
    "    \n",
    "git2net.mine_git_repo(git_repo_dir, sqlite_db_file, max_modifications=max_modifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the commits that had more than 100 files modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git2net.mining_state_summary(git_repo_dir, sqlite_db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database modification\n",
    "Replacing the aliases belonging to the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(sqlite_db_file)\n",
    "\n",
    "# Query the db\n",
    "data = pd.read_sql(\"\"\"SELECT * FROM commits\"\"\", con)\n",
    "\n",
    "# Get all the name-email pairs\n",
    "names = data[['author_email', 'author_name']].copy()\n",
    "names.groupby(['author_email', 'author_name']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "# After adding the similar names to the aliases.json, replace the values\n",
    "#with open('aliases.json') as file:\n",
    "#    aliases = json.load(file)\n",
    "\n",
    "#data = data.replace(aliases)\n",
    "\n",
    "# Save changes in db\n",
    "#data.to_sql('commits', con, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-author networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t, node_info, edge_info = git2net.get_coediting_network(sqlite_db_file)\n",
    "pp.Network.from_temporal_network(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which files were edited by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t, node_info, edge_info = git2net.get_bipartite_network(sqlite_db_file)\n",
    "n = pp.Network.from_temporal_network(t)\n",
    "\n",
    "colour_map = {'author': '#73D2DE', 'file': '#2E5EAA'}\n",
    "node_color = {node: colour_map[node_info['class'][node]] for node in n.nodes}\n",
    "pp.visualisation.plot(n, node_color=node_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-authorship network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n, node_info, edge_info = git2net.get_coauthorship_network(sqlite_db_file)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is too complex because we consider the whole timeframe of the repository since its creation. Therefore we need to filter the time dimensin, and in order to do that we nee to find the first and last commit in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(sqlite_db_file)\n",
    "max_date = datetime.strptime(pd.read_sql_query(\"SELECT max(committer_date) as max FROM commits\", db)['max'].item(), '%Y-%m-%d %H:%M:%S')\n",
    "min_date = datetime.strptime(pd.read_sql_query(\"SELECT min(committer_date) as min FROM commits\", db)['min'].item(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print('Min date: ', min_date)\n",
    "print('Max date: ', max_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order not to select an 'empty' time period (relatively few commits, e.g. holiday season), it's also worth observing the number of commits over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdCommits = pd.read_sql_query(\"SELECT * FROM commits\", db)\n",
    "\n",
    "days = {(min_date+timedelta(days=x)).date() : 0 for x in range((max_date-min_date).days + 1)}\n",
    "\n",
    "commit_dates = pdCommits['committer_date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').date()).value_counts()\n",
    "\n",
    "for key in commit_dates.keys():\n",
    "    days[key] = commit_dates.get(key)\n",
    "\n",
    "keys = days.keys()\n",
    "values = days.values()\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(keys, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the year 2020 based on the plot, as that was the busiest year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_from = datetime(2020, 1, 1)\n",
    "time_to = datetime(2020, 12, 31)\n",
    "n, node_info, edge_info = git2net.get_coauthorship_network(sqlite_db_file, time_from=time_from, time_to=time_to)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the node size based on the number of degrees each author has in the network. This emphasizes who collaborate more with the others in the given timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "node_style = zip(n.nodes, n.node_properties('degree'))\n",
    "style = {}\n",
    "style['node_size'] = {v:3+u for v,u in node_style}\n",
    "pp.visualisation.plot(n, **style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartite networks\n",
    "Because our network changes over time, we would like to visualize each year consecutively one after the other. We can use the pathpy temporal networks for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_network(sqlite_db_file, min_date, max_date):\n",
    "    start = int(datetime.timestamp(min_date))\n",
    "    end = int(datetime.timestamp(max_date))\n",
    "    t, node_info, edge_info = git2net.get_bipartite_network(sqlite_db_file)\n",
    "    n = pp.Network.from_temporal_network(t)\n",
    "\n",
    "    new_n = copy.deepcopy(n)\n",
    "    \n",
    "    for node in n.nodes:\n",
    "        if node_info['class'][node] == 'file':\n",
    "            new_n.remove_node(node)\n",
    "\n",
    "    for node in new_n.nodes:\n",
    "        for f in n.successors[node]:\n",
    "            for pre in n.predecessors[f]:\n",
    "                if not node == pre:\n",
    "                    new_n.add_edge(node, pre)\n",
    "\n",
    "    \n",
    "    return new_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_from = datetime(2015, 1, 1)\n",
    "time_to = datetime(2015, 2, 6)\n",
    "interval = timedelta(days=30)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "t2 = pp.TemporalNetwork()\n",
    "for i in range(math.ceil((time_to - time_from - interval)/delta)):\n",
    "    start = time_from + i * delta\n",
    "    end = time_from + i * delta + interval\n",
    "    network = collab_network(sqlite_db_file, start, end)\n",
    "\n",
    "    for edge in network.edges:\n",
    "        t2.add_edge(edge[0], edge[1])\n",
    "n2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pp.temporal_network)\n",
    "\n",
    "t2 = pp.TemporalNetwork()\n",
    "years = []\n",
    "\n",
    "for year in range(min_date.year, max_date.year):\n",
    "    print('Processing year: ', year)\n",
    "    n, node_info, edge_info = git2net.get_coauthorship_network(sqlite_db_file, time_from=datetime(year, 1,1), time_to=datetime(year, 12, 31))\n",
    "    years.append(n)\n",
    "    for edge in list(n.edges.keys()):\n",
    "        t2.add_edge(edge[0].replace(' ','_'),edge[1].replace(' ','_'),year)\n",
    "\n",
    "# t2 = t.filter_edges(lambda v, w, time: True if (time_from <= time <= time_to) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {    \n",
    "  'ts_per_frame': 1, \n",
    "  'ms_per_frame': 2000,\n",
    "  'look_ahead': 0, \n",
    "  'look_behind': 0, \n",
    "  'node_size': 15, \n",
    "  'inactive_edge_width': 2,\n",
    "  'active_edge_width': 4, \n",
    "  'label_color' : '#000000',\n",
    "  'label_size' : '8px',\n",
    "  'label_offset': [0,5]\n",
    "  }\n",
    "print(t2)\n",
    "pp.visualisation.plot(t2, **style, width=1000, height=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}